{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ccd7b1f4-4c49-4c48-8399-8b9ceef0b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/CT_MPS_mini/CT`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"CT\")\n",
    "using CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "484c31bc-19ce-4b04-b4af-2b0e62cde5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mProject\u001b[22m\u001b[39m CT v0.1.0\n",
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/CT_MPS_mini/CT/Project.toml`\n",
      "  \u001b[90m[c7e460c6] \u001b[39mArgParse v1.2.0\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.5.0\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[9136182c] \u001b[39mITensors v0.6.16\n",
      "  \u001b[90m[682c06a0] \u001b[39mJSON v0.21.4\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[33e6dc65] \u001b[39mMKL v0.7.0\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.5\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[9f0aa9f4] \u001b[39mTCIITensorConversion v0.1.4\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[b261b2ec] \u001b[39mTensorCrossInterpolation v0.9.10\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[a759f4b9] \u001b[39mTimerOutputs v0.5.24\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\n"
     ]
    }
   ],
   "source": [
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dd5c3d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1, 4, 2, 3]\n",
      "[1, 3, 4, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 0, 1], 5)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark adder_MPO\n",
    "using ITensors\n",
    "include(\"CT/src/test_adder_MPO.jl\")\n",
    "# initialize random state\n",
    "using .CT: _initialize_basis, _initialize_vector, P_MPO, XI_MPO, I_MPO, adder_MPO\n",
    "using Random\n",
    "L = 4\n",
    "ancilla = 0\n",
    "folded = true\n",
    "seed_vec = 123457\n",
    "xj = Set([1//3, 2//3])\n",
    "i1 = 1\n",
    "p_ctrl = 1.0\n",
    "p_proj = 0.0\n",
    "_maxdim = 50\n",
    "_cutoff = 1e-15\n",
    "seed = 123457\n",
    "x0 = nothing\n",
    "qubit_site, ram_phy, phy_ram, phy_list = _initialize_basis(L, ancilla, folded)\n",
    "println(phy_list)\n",
    "println(ram_phy)\n",
    "println(phy_ram)\n",
    "rng = MersenneTwister(seed_vec)\n",
    "rng_vec = seed_vec === nothing ? rng : MersenneTwister(seed_vec)\n",
    "# initial_state = _initialize_vector(L, ancilla, x0, folded, qubit_site, ram_phy, phy_ram, phy_list, rng_vec, _cutoff, _maxdim);\n",
    "# println(initial_state)\n",
    "initial_state = productMPS(qubit_site, [1,2,2,1])\n",
    "shift_1_3_bits, shift_1_3_amount = fraction_to_binary_shift(1, 3, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0ba16336",
   "metadata": {},
   "outputs": [],
   "source": [
    "ram_pos = 1\n",
    "qubit_site = siteinds(initial_state)\n",
    "shift_bit = shift_1_3_bits[ram_phy[ram_pos]]\n",
    "phy_pos = phy_ram[ram_pos]\n",
    "T_left_ind = Index(2, \"Carry,c=$(ram_pos-1)\")\n",
    "T_right_ind = Index(2, \"Carry,c=$(ram_pos)\")\n",
    "T = create_addition_tensor_with_carry(shift_bit, qubit_site[ram_pos], prime(qubit_site[ram_pos]), T_left_ind, T_right_ind);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a134cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "((dim=2|id=925|\"Qubit,Site,n=1\"), (dim=2|id=925|\"Qubit,Site,n=1\")', (dim=2|id=847|\"Carry,c=0\"), (dim=2|id=426|\"Carry,c=1\"))\n",
      "[0.0 0.0; 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "println(shift_bit)\n",
    "println(T.tensor.inds)\n",
    "T_array = array(T)\n",
    "println(T_array[:,:,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d8b9f661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITensor ord=3\n",
      "Dim 1: (dim=2|id=796|\"Qubit,Site,n=4\")\n",
      "Dim 2: (dim=2|id=796|\"Qubit,Site,n=4\")'\n",
      "Dim 3: (dim=2|id=911|\"Carry,c_out\")\n",
      "NDTensors.Dense{Float64, Vector{Float64}}\n",
      " 2×2×2\n",
      "[:, :, 1] =\n",
      " 0.0  1.0\n",
      " 0.0  0.0\n",
      "\n",
      "[:, :, 2] =\n",
      " 0.0  0.0\n",
      " 1.0  0.0\n"
     ]
    }
   ],
   "source": [
    "c_in = Index(2, \"Carry,c_in\")\n",
    "c_out = Index(2, \"Carry,c_out\")\n",
    "T_last = create_addition_tensor_with_carry(1, qubit_site[L], prime(qubit_site[L]), c_in, c_out)\n",
    "\n",
    "lsb_tensor = ITensor(c_in)\n",
    "lsb_tensor[c_in=>1] = 1.0\n",
    "T_last = T_last * lsb_tensor\n",
    "println(T_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9fed7d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor indices: ((dim=3|id=807|\"i\"), (dim=4|id=423|\"j\"), (dim=2|id=658|\"k\"))\n",
      "Index dimensions: [3, 4, 2]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access Tuple{Int64} at index [0]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access Tuple{Int64} at index [0]",
      "",
      "Stacktrace:",
      " [1] \u001b[0m\u001b[1mgetindex\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtuple.jl:31\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [2] \u001b[0m\u001b[1m(::NDTensors.var\"#9#10\"{Tuple{Int64}, Tuple{Nothing}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mi\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[32mNDTensors\u001b[39m \u001b[90m~/julia_depot/packages/NDTensors/gdQSG/src/\u001b[39m\u001b[90m\u001b[4mtupletools.jl:43\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [3] \u001b[0m\u001b[1mntuple\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mntuple.jl:50\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [4] \u001b[0m\u001b[1m_permute\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[90m~/julia_depot/packages/NDTensors/gdQSG/src/\u001b[39m\u001b[90m\u001b[4mtupletools.jl:43\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
      " [5] \u001b[0m\u001b[1mpermute\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mTuple\u001b[90m{Int64}\u001b[39m, \u001b[90mperm\u001b[39m::\u001b[0mTuple\u001b[90m{Int64, Int64, Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[32mNDTensors\u001b[39m \u001b[90m~/julia_depot/packages/NDTensors/gdQSG/src/\u001b[39m\u001b[90m\u001b[4mtupletools.jl:50\u001b[24m\u001b[39m",
      " [6] \u001b[0m\u001b[1m_getindex\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mT\u001b[39m::\u001b[0mNDTensors.DenseTensor\u001b[90m{Float64, 3, Tuple{Index{Int64}, Index{Int64}, Index{Int64}}, NDTensors.Dense{Float64, Vector{Float64}}}\u001b[39m, \u001b[90mivs\u001b[39m::\u001b[0mPair\u001b[90m{Index{Int64}, Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[36mITensors.ITensorsSiteTypesExt\u001b[39m \u001b[90m~/julia_depot/packages/ITensors/oOwvi/src/lib/ITensorsSiteTypesExt/src/\u001b[39m\u001b[90m\u001b[4mITensorsSiteTypesExt.jl:30\u001b[24m\u001b[39m",
      " [7] \u001b[0m\u001b[1mgetindex\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mT\u001b[39m::\u001b[0mITensor, \u001b[90mivs\u001b[39m::\u001b[0mPair\u001b[90m{Index{Int64}, Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
      "\u001b[90m   @\u001b[39m \u001b[36mITensors\u001b[39m \u001b[90m~/julia_depot/packages/ITensors/oOwvi/src/\u001b[39m\u001b[90m\u001b[4mitensor.jl:1117\u001b[24m\u001b[39m",
      " [8] top-level scope",
      "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[220]:15\u001b[24m\u001b[39m"
     ]
    }
   ],
   "source": [
    "using ITensors\n",
    "\n",
    "# Create indices with explicit dimensions\n",
    "i = Index(3, \"i\")\n",
    "j = Index(4, \"j\") \n",
    "k = Index(2, \"k\")\n",
    "T = randomITensor(i, j, k)\n",
    "\n",
    "# Check the tensor structure\n",
    "println(\"Tensor indices: \", inds(T))\n",
    "println(\"Index dimensions: \", [dim(idx) for idx in inds(T)])\n",
    "\n",
    "# Make sure the value is within bounds (1-indexed in Julia)\n",
    "# For index i with dimension 3, valid values are 1, 2, 3\n",
    "T_fixed = T[i => 1]  # or 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed97f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index{Int64}[(dim=2|id=309|\"Carry,c=0\"), (dim=2|id=71|\"Qubit,Site,n=1\"), (dim=1|id=329|\"Link,l=1\")]\n",
      "Index{Int64}[(dim=2|id=968|\"Carry,c=1\"), (dim=1|id=852|\"Link,l=1\"), (dim=2|id=82|\"Qubit,Site,n=2\"), (dim=2|id=804|\"Carry,c=2\"), (dim=1|id=66|\"Link,l=2\")]\n",
      "ITensor ord=2\n",
      "Dim 1: (dim=2|id=71|\"Qubit,Site,n=1\")\n",
      "Dim 2: (dim=1|id=852|\"Link,l=1\")\n",
      "NDTensors.Dense{Float64, Vector{Float64}}\n",
      " 2×1\n",
      " 0.6484197773255047\n",
      " 0.6484197773255047\n",
      "Cut between sites 1 and 2: [0.9999999999999997]\n",
      "Cut between sites 2 and 3: [0.9999999999999996, 0.0]\n",
      "Cut between sites 3 and 4: [0.9999999999999996]\n",
      "Cut between sites 1 and 2: [0.0]\n",
      "Cut between sites 2 and 3: [0.0, 0.0]\n",
      "Cut between sites 3 and 4: [0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPS\n",
       "[1] ((dim=2|id=71|\"Qubit,Site,n=1\"), (dim=1|id=852|\"Link,l=1\"))\n",
       "[2] ((dim=4|id=459|\"Link,l=2\"), (dim=2|id=82|\"Qubit,Site,n=2\"), (dim=1|id=852|\"Link,l=1\"))\n",
       "[3] ((dim=4|id=784|\"Link,l=3\"), (dim=4|id=459|\"Link,l=2\"), (dim=2|id=712|\"Qubit,Site,n=3\"))\n",
       "[4] ((dim=4|id=784|\"Link,l=3\"), (dim=2|id=959|\"Qubit,Site,n=4\"))\n"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"global_adder_passthrough.jl\")\n",
    "initial_state = global_adder_folded(initial_state, ram_phy, shift_1_3_bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786985bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function print_mpo_as_matrix(mpo, L)\n",
    "#     println(\"\\nMPO as matrix:\")\n",
    "    \n",
    "#     # Contract the entire MPO to get the matrix representation\n",
    "#     mpo_tensor = contract(mpo)\n",
    "    \n",
    "#     # The tensor has indices (s1', s2', ..., sL', s1, s2, ..., sL)\n",
    "#     # We need to reshape it into a matrix where the first L indices are rows\n",
    "#     # and the last L indices are columns\n",
    "    \n",
    "#     # Get the tensor as an array\n",
    "#     tensor_array = Array(mpo_tensor, inds(mpo_tensor)...)\n",
    "    \n",
    "#     # Reshape to matrix: first 2^L entries are rows, next 2^L are columns\n",
    "#     matrix = reshape(tensor_array, 2^L, 2^L)\n",
    "    \n",
    "#     # Create basis labels\n",
    "#     basis_labels = []\n",
    "#     for i in 0:2^L-1\n",
    "#         bits = string(i, base=2, pad=L)\n",
    "#         push!(basis_labels, \"|$bits⟩\")\n",
    "#     end\n",
    "    \n",
    "#     # Print header\n",
    "#     print(\"      \")\n",
    "#     for j in 1:2^L\n",
    "#         print(\"$(basis_labels[j])  \")\n",
    "#     end\n",
    "#     println()\n",
    "    \n",
    "#     # Print matrix rows\n",
    "#     for i in 1:2^L\n",
    "#         print(\"$(basis_labels[i]) \")\n",
    "#         for j in 1:2^L\n",
    "#             val = abs(matrix[i, j])\n",
    "#             if val > 0.5\n",
    "#                 print(\"  1   \")\n",
    "#             else\n",
    "#                 print(\"  0   \")\n",
    "#             end\n",
    "#         end\n",
    "#         println()\n",
    "#     end\n",
    "    \n",
    "#     return matrix\n",
    "# end\n",
    "\n",
    "# print_mpo_as_matrix(mpo, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb25c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function print_mpo_as_matrix(mpo, L)\n",
    "#     println(\"\\nMPO as matrix:\")\n",
    "    \n",
    "#     # Contract the entire MPO to get the matrix representation\n",
    "#     mpo_tensor = contract(mpo)\n",
    "    \n",
    "#     # The tensor has indices (s1', s2', ..., sL', s1, s2, ..., sL)\n",
    "#     # We need to reshape it into a matrix where the first L indices are rows\n",
    "#     # and the last L indices are columns\n",
    "    \n",
    "#     # Get the tensor as an array\n",
    "#     tensor_array = Array(mpo_tensor, inds(mpo_tensor)...)\n",
    "    \n",
    "#     # Reshape to matrix: first 2^L entries are rows, next 2^L are columns\n",
    "#     matrix = reshape(tensor_array, 2^L, 2^L)\n",
    "    \n",
    "#     # Create basis labels\n",
    "#     basis_labels = []\n",
    "#     for i in 0:2^L-1\n",
    "#         bits = string(i, base=2, pad=L)\n",
    "#         push!(basis_labels, \"|$bits⟩\")\n",
    "#     end\n",
    "    \n",
    "#     # Print header\n",
    "#     print(\"      \")\n",
    "#     for j in 1:2^L\n",
    "#         print(\"$(basis_labels[j])  \")\n",
    "#     end\n",
    "#     println()\n",
    "    \n",
    "#     # Print matrix rows\n",
    "#     for i in 1:2^L\n",
    "#         print(\"$(basis_labels[i]) \")\n",
    "#         for j in 1:2^L\n",
    "#             val = abs(matrix[i, j])\n",
    "#             if val > 0.5\n",
    "#                 print(\"  1   \")\n",
    "#             else\n",
    "#                 print(\"  0   \")\n",
    "#             end\n",
    "#         end\n",
    "#         println()\n",
    "#     end\n",
    "    \n",
    "#     return matrix\n",
    "# end\n",
    "\n",
    "# print_mpo_as_matrix(mpo, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function print_mpo_as_matrix(mpo, L)\n",
    "#     println(\"\\nMPO as matrix:\")\n",
    "    \n",
    "#     # Contract the entire MPO to get the matrix representation\n",
    "#     mpo_tensor = contract(mpo)\n",
    "    \n",
    "#     # The tensor has indices (s1', s2', ..., sL', s1, s2, ..., sL)\n",
    "#     # We need to reshape it into a matrix where the first L indices are rows\n",
    "#     # and the last L indices are columns\n",
    "    \n",
    "#     # Get the tensor as an array\n",
    "#     tensor_array = Array(mpo_tensor, inds(mpo_tensor)...)\n",
    "    \n",
    "#     # Reshape to matrix: first 2^L entries are rows, next 2^L are columns\n",
    "#     matrix = reshape(tensor_array, 2^L, 2^L)\n",
    "    \n",
    "#     # Create basis labels\n",
    "#     basis_labels = []\n",
    "#     for i in 0:2^L-1\n",
    "#         bits = string(i, base=2, pad=L)\n",
    "#         push!(basis_labels, \"|$bits⟩\")\n",
    "#     end\n",
    "    \n",
    "#     # Print header\n",
    "#     print(\"      \")\n",
    "#     for j in 1:2^L\n",
    "#         print(\"$(basis_labels[j])  \")\n",
    "#     end\n",
    "#     println()\n",
    "    \n",
    "#     # Print matrix rows\n",
    "#     for i in 1:2^L\n",
    "#         print(\"$(basis_labels[i]) \")\n",
    "#         for j in 1:2^L\n",
    "#             val = abs(matrix[i, j])\n",
    "#             if val > 0.5\n",
    "#                 print(\"  1   \")\n",
    "#             else\n",
    "#                 print(\"  0   \")\n",
    "#             end\n",
    "#         end\n",
    "#         println()\n",
    "#     end\n",
    "    \n",
    "#     return matrix\n",
    "# end\n",
    "\n",
    "# print_mpo_as_matrix(mpo, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function print_mpo_as_matrix(mpo, L)\n",
    "#     println(\"\\nMPO as matrix:\")\n",
    "    \n",
    "#     # Contract the entire MPO to get the matrix representation\n",
    "#     mpo_tensor = contract(mpo)\n",
    "    \n",
    "#     # The tensor has indices (s1', s2', ..., sL', s1, s2, ..., sL)\n",
    "#     # We need to reshape it into a matrix where the first L indices are rows\n",
    "#     # and the last L indices are columns\n",
    "    \n",
    "#     # Get the tensor as an array\n",
    "#     tensor_array = Array(mpo_tensor, inds(mpo_tensor)...)\n",
    "    \n",
    "#     # Reshape to matrix: first 2^L entries are rows, next 2^L are columns\n",
    "#     matrix = reshape(tensor_array, 2^L, 2^L)\n",
    "    \n",
    "#     # Create basis labels\n",
    "#     basis_labels = []\n",
    "#     for i in 0:2^L-1\n",
    "#         bits = string(i, base=2, pad=L)\n",
    "#         push!(basis_labels, \"|$bits⟩\")\n",
    "#     end\n",
    "    \n",
    "#     # Print header\n",
    "#     print(\"      \")\n",
    "#     for j in 1:2^L\n",
    "#         print(\"$(basis_labels[j])  \")\n",
    "#     end\n",
    "#     println()\n",
    "    \n",
    "#     # Print matrix rows\n",
    "#     for i in 1:2^L\n",
    "#         print(\"$(basis_labels[i]) \")\n",
    "#         for j in 1:2^L\n",
    "#             val = abs(matrix[i, j])\n",
    "#             if val > 0.5\n",
    "#                 print(\"  1   \")\n",
    "#             else\n",
    "#                 print(\"  0   \")\n",
    "#             end\n",
    "#         end\n",
    "#         println()\n",
    "#     end\n",
    "    \n",
    "#     return matrix\n",
    "# end\n",
    "\n",
    "# print_mpo_as_matrix(mpo, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd89f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create 2D identity matrices to compare against\n",
    "# expected_identity = [1.0 0.0; 0.0 1.0]\n",
    "\n",
    "# # Extract T[1,:,:,1] as a matrix\n",
    "# slice_1 = zeros(2, 2)\n",
    "# for i in 1:2, j in 1:2\n",
    "#     slice_1[i, j] = T[i1 => 1, i2 => i, i3 => j, i4 => 1]\n",
    "# end\n",
    "\n",
    "# # Extract T[2,:,:,2] as a matrix  \n",
    "# slice_2 = zeros(2, 2)\n",
    "# for i in 1:2, j in 1:2\n",
    "#     slice_2[i, j] = T[i1 => 2, i2 => i, i3 => j, i4 => 2]\n",
    "# end\n",
    "\n",
    "# println(\"T[1,:,:,1] =\")\n",
    "# display(slice_1)\n",
    "# println(\"Expected identity =\")\n",
    "# display(expected_identity)\n",
    "# println(\"Are they equal? \", slice_1 ≈ expected_identity)\n",
    "\n",
    "# println(\"\\nT[2,:,:,2] =\")\n",
    "# display(slice_2)\n",
    "# println(\"Are they equal? \", slice_2 ≈ expected_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19865e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function print_mpo_as_matrix(mpo, L)\n",
    "#     println(\"\\nMPO as matrix:\")\n",
    "    \n",
    "#     # Contract the entire MPO to get the matrix representation\n",
    "#     mpo_tensor = contract(mpo)\n",
    "    \n",
    "#     # The tensor has indices (s1', s2', ..., sL', s1, s2, ..., sL)\n",
    "#     # We need to reshape it into a matrix where the first L indices are rows\n",
    "#     # and the last L indices are columns\n",
    "    \n",
    "#     # Get the tensor as an array\n",
    "#     tensor_array = Array(mpo_tensor, inds(mpo_tensor)...)\n",
    "    \n",
    "#     # Reshape to matrix: first 2^L entries are rows, next 2^L are columns\n",
    "#     matrix = reshape(tensor_array, 2^L, 2^L)\n",
    "    \n",
    "#     # Create basis labels\n",
    "#     basis_labels = []\n",
    "#     for i in 0:2^L-1\n",
    "#         bits = string(i, base=2, pad=L)\n",
    "#         push!(basis_labels, \"|$bits⟩\")\n",
    "#     end\n",
    "    \n",
    "#     # Print header\n",
    "#     print(\"      \")\n",
    "#     for j in 1:2^L\n",
    "#         print(\"$(basis_labels[j])  \")\n",
    "#     end\n",
    "#     println()\n",
    "    \n",
    "#     # Print matrix rows\n",
    "#     for i in 1:2^L\n",
    "#         print(\"$(basis_labels[i]) \")\n",
    "#         for j in 1:2^L\n",
    "#             val = abs(matrix[i, j])\n",
    "#             if val > 0.5\n",
    "#                 print(\"  1   \")\n",
    "#             else\n",
    "#                 print(\"  0   \")\n",
    "#             end\n",
    "#         end\n",
    "#         println()\n",
    "#     end\n",
    "    \n",
    "#     return matrix\n",
    "# end\n",
    "\n",
    "# print_mpo_as_matrix(mpo, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2af954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61790ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # debug \n",
    "# # haining\n",
    "# using .CT: add1, power_mpo\n",
    "# add1_mpo=MPO(add1(i1,L,phy_ram,phy_list),qubit_site)\n",
    "# add1_6,add1_3=power_mpo(add1_mpo,[div(2^L,6)+1,div(2^L,3)])\n",
    "\n",
    "# # tao\n",
    "# # mpo, bond_dims, dense_mat, A_tensor = mpo_adder_1_3(L, qubit_site, ram_phy, phy_ram, phy_list, folded);\n",
    "# shift_1_3_bits, shift_1_3_amount = fraction_to_binary_shift(1, 3, L)\n",
    "# mpo = create_binary_addition_mpo(shift_1_3_bits, qubit_site, phy_ram, phy_list, ram_phy)\n",
    "\n",
    "# result_h = initial_state * add1_3\n",
    "# result_t = initial_state * mpo\n",
    "# n = 3\n",
    "# println(result_h[n])\n",
    "# println(result_t[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
