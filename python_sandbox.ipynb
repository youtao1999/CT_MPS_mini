{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20cd6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/scratch/ty296/CT_MPS_mini')\n",
    "from read_hdf5_func import von_neumann_entropy_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b45f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def postprocessing(sv_combined=\"/scratch/ty296/hdf5_data_combined/sv_combined.h5\", dir_name='/scratch/ty296/hdf5_data/p_ctrl0.4'):\n",
    "    h5_files = glob.glob(os.path.join(dir_name, '*.h5'))\n",
    "    with h5py.File(sv_combined, 'w') as f_combined:\n",
    "        counter = 0\n",
    "        for file in tqdm.tqdm(h5_files):\n",
    "            with h5py.File(file, 'r') as f:\n",
    "                metadata = f['metadata']\n",
    "                singular_values = f['singular_values']\n",
    "                for result_group in metadata.keys():\n",
    "                    counter += 1\n",
    "                    p_proj = metadata[result_group]['p_proj'][()]\n",
    "                    p_ctrl = metadata[result_group]['p_ctrl'][()]\n",
    "                    L = metadata[result_group]['args']['L'][()]\n",
    "                    maxbond = metadata[result_group]['max_bond'][()]\n",
    "                    sv_arr = singular_values[result_group][()]\n",
    "                    group_name = f'real{counter}'\n",
    "                    grp = f_combined.create_dataset(group_name, data=sv_arr)\n",
    "                    grp.attrs['p_proj'] = p_proj\n",
    "                    grp.attrs['p_ctrl'] = p_ctrl\n",
    "                    grp.attrs['L'] = L\n",
    "                    grp.attrs['maxbond'] = maxbond\n",
    "\n",
    "def calculate_mean_and_error(ee_values: List[float]) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate mean and standard error of the mean.\"\"\"\n",
    "    ee_array = np.array(ee_values)\n",
    "    mean = np.mean(ee_array)\n",
    "    sem = np.std(ee_array, ddof=1) / np.sqrt(len(ee_array))\n",
    "    return mean, sem\n",
    "\n",
    "def calculate_variance_and_error(ee_values: List[float]) -> Tuple[float, float]:\n",
    "    \"\"\"Calculate variance and standard error of variance.\"\"\"\n",
    "    ee_array = np.array(ee_values)\n",
    "    variance = np.var(ee_array, ddof=1)\n",
    "    # Standard error of variance approximation\n",
    "    n = len(ee_array)\n",
    "    se_var = variance * np.sqrt(2.0 / (n - 1))\n",
    "    return variance, se_var\n",
    "\n",
    "def h5_to_csv(hdf5_combined, n, threshold, save_folder = '/scratch/ty296/plots'):\n",
    "    with h5py.File(hdf5_combined, 'r') as f:\n",
    "        from collections import defaultdict\n",
    "        groups = defaultdict(list)\n",
    "        for real_key in f.keys():\n",
    "            s0 = von_neumann_entropy_sv(f[real_key][()], n=n, positivedefinite=False, threshold=threshold)\n",
    "            # print(f[real_key].attrs['p_proj'],f[real_key].attrs['p_ctrl'],f[real_key].attrs['L'],f[real_key].attrs['maxbond'],s0)\n",
    "            key_val = (f[real_key].attrs['L'],f[real_key].attrs['p_ctrl'],f[real_key].attrs['p_proj'])\n",
    "            groups[key_val].append(s0)\n",
    "        \n",
    "\n",
    "        data = []\n",
    "        for key_val, s0_list in groups.items():\n",
    "            mean, sem = calculate_mean_and_error(s0_list)\n",
    "            variance, se_var = calculate_variance_and_error(s0_list)\n",
    "            # print(key_val, \"mean\", mean, \"sem\", sem, \"variance\", variance, \"se_var\", se_var)\n",
    "            data.append(list(key_val) + [mean, sem, variance, se_var])\n",
    "        print(data)\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['L', 'p_ctrl', 'p_proj', 'mean', 'sem', 'variance', 'se_var'])\n",
    "        # save the data to a csv file\n",
    "        csv_path = os.path.join(save_folder, f's{n}_threshold{threshold}.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "def plot_from_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Plot p_proj vs mean±sem and p_proj vs variance±se_var from CSV file\n",
    "    CSV should have columns: L, p_ctrl, p_proj, mean, sem, variance, se_var\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Read CSV data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Organize data by L values\n",
    "    plot_data = {}\n",
    "    for _, row in df.iterrows():\n",
    "        L = row['L']\n",
    "        if L not in plot_data:\n",
    "            plot_data[L] = {'p_proj': [], 'mean': [], 'sem': [], 'variance': [], 'se_var': []}\n",
    "        \n",
    "        plot_data[L]['p_proj'].append(row['p_proj'])\n",
    "        plot_data[L]['mean'].append(row['mean'])\n",
    "        plot_data[L]['sem'].append(row['sem'])\n",
    "        plot_data[L]['variance'].append(row['variance'])\n",
    "        plot_data[L]['se_var'].append(row['se_var'])\n",
    "\n",
    "    # Create plots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Plot 1: p_proj vs mean ± sem\n",
    "    for L in sorted(plot_data.keys()):\n",
    "        data = plot_data[L]\n",
    "        # Sort by p_proj for cleaner lines\n",
    "        sorted_indices = np.argsort(data['p_proj'])\n",
    "        p_proj_sorted = np.array(data['p_proj'])[sorted_indices]\n",
    "        mean_sorted = np.array(data['mean'])[sorted_indices]\n",
    "        sem_sorted = np.array(data['sem'])[sorted_indices]\n",
    "        \n",
    "        ax1.errorbar(p_proj_sorted, mean_sorted, yerr=sem_sorted, \n",
    "                    label=f'L={L}', marker='o', capsize=5, capthick=2)\n",
    "\n",
    "    ax1.set_xlabel('p_proj')\n",
    "    ax1.set_ylabel('Mean Entropy ± SEM')\n",
    "    ax1.set_title('Mean Entropy vs p_proj for Different L')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: p_proj vs variance ± se_var\n",
    "    for L in sorted(plot_data.keys()):\n",
    "        data = plot_data[L]\n",
    "        # Sort by p_proj for cleaner lines\n",
    "        sorted_indices = np.argsort(data['p_proj'])\n",
    "        p_proj_sorted = np.array(data['p_proj'])[sorted_indices]\n",
    "        variance_sorted = np.array(data['variance'])[sorted_indices]\n",
    "        se_var_sorted = np.array(data['se_var'])[sorted_indices]\n",
    "        \n",
    "        ax2.errorbar(p_proj_sorted, variance_sorted, yerr=se_var_sorted, \n",
    "                    label=f'L={L}', marker='s', capsize=5, capthick=2)\n",
    "\n",
    "    ax2.set_xlabel('p_proj')\n",
    "    ax2.set_ylabel('Variance ± SE')\n",
    "    ax2.set_title('Variance vs p_proj for Different L')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff63fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 9/682 [00:08<09:59,  1.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-1\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mpostprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msv_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m h5_to_csv(sv_combined, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Then plot from the generated CSV:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36mpostprocessing\u001b[0;34m(sv_combined, dir_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m p_proj \u001b[38;5;241m=\u001b[39m metadata[result_group][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_proj\u001b[39m\u001b[38;5;124m'\u001b[39m][()]\n\u001b[0;32m---> 20\u001b[0m p_ctrl \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresult_group\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp_ctrl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m L \u001b[38;5;241m=\u001b[39m metadata[result_group][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m][()]\n\u001b[1;32m     22\u001b[0m maxbond \u001b[38;5;241m=\u001b[39m metadata[result_group][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_bond\u001b[39m\u001b[38;5;124m'\u001b[39m][()]\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/dataset.py:800\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;124;03m* Boolean \"mask\" array indexing\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    798\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (args,)\n\u001b[0;32m--> 800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_read_ok\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_reader\u001b[38;5;241m.\u001b[39mread(args)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/base.py:532\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 532\u001b[0m value \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/dataset.py:782\u001b[0m, in \u001b[0;36mDataset._fast_read_ok\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fast_read_ok\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    780\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 782\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extent_type\u001b[49m \u001b[38;5;241m==\u001b[39m h5s\u001b[38;5;241m.\u001b[39mSIMPLE\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mget_type(), (h5t\u001b[38;5;241m.\u001b[39mTypeIntegerID, h5t\u001b[38;5;241m.\u001b[39mTypeFloatID))\n\u001b[1;32m    784\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/h5py/_hl/base.py:532\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 532\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(obj)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# First generate CSV using h5_to_csv function:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sv_combined = \"/scratch/ty296/hdf5_data_combined/sv_combined.h5\"\n",
    "    dir_name = '/scratch/ty296/hdf5_data/p_ctrl0.4'\n",
    "    save_folder = '/scratch/ty296/plots'\n",
    "    n = 0\n",
    "    threshold = 1e-1\n",
    "    postprocessing(sv_combined, dir_name)\n",
    "\n",
    "    df = h5_to_csv(sv_combined, n=0, threshold=1e-1)\n",
    "\n",
    "    # Then plot from the generated CSV:\n",
    "    csv_path = os.path.join(save_folder, f's{n}_threshold{threshold}.csv')\n",
    "    plot_from_csv(csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple Python 3.9.6",
   "language": "python",
   "name": "simple-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
