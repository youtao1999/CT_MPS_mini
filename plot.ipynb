{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/ty296\n"
     ]
    }
   ],
   "source": [
    "hdf5_data_path = '/scratch/ty296/hdf5_data/'\n",
    "groupname = 'L'\n",
    "p_fixed_name = 'p_ctrl'\n",
    "p_fixed_value = 0.4\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import sys\n",
    "sys.path.append('/scratch/ty296/CT_MPS_mini')\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from read_hdf5_func import read_hdf5_file, von_neumann_entropy_sv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical functions\n",
    "def mean_func(x):\n",
    "    return x.mean()\n",
    "\n",
    "def sem_func(x):\n",
    "    \"\"\"Standard Error of Mean\"\"\"\n",
    "    return x.std() / np.sqrt(len(x))\n",
    "\n",
    "def variance_func(x):\n",
    "    return x.var()\n",
    "\n",
    "def sev_func(x):\n",
    "    \"\"\"Standard Error of Variance\"\"\"\n",
    "    n = len(x)\n",
    "    if n <= 1:\n",
    "        return np.nan\n",
    "    # Standard error of variance formula\n",
    "    return x.var() * np.sqrt(2 / (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_processor:\n",
    "    def __init__(self, dir_name, n, threshold):\n",
    "        self.dir_name = dir_name\n",
    "        self.n = n\n",
    "        self.threshold = threshold\n",
    "        self.df_all_data = self.df_all_data()\n",
    "    \n",
    "    def df_all_data(self):\n",
    "\n",
    "        def extract_tuples(hdf5_file_path, n, threshold):\n",
    "            all_data = []\n",
    "            single_file_data = read_hdf5_file(hdf5_file_path, load_sv_arrays=True)\n",
    "            for data_point_num in range(len(single_file_data)):\n",
    "                L = single_file_data[data_point_num]['args']['L']\n",
    "                p_ctrl = single_file_data[data_point_num]['p_ctrl']\n",
    "                p_proj = single_file_data[data_point_num]['p_proj']\n",
    "                s_0 = von_neumann_entropy_sv(single_file_data[data_point_num]['sv_arr'], n=n, positivedefinite=False, threshold=threshold)\n",
    "                data_point = (L, p_ctrl, p_proj, s_0)\n",
    "                all_data.append(data_point)\n",
    "            return all_data\n",
    "        \n",
    "        df_all_data = pd.DataFrame()\n",
    "        # for file_num in tqdm.tqdm(range(len(os.listdir(dir_name)))):\n",
    "        for file_num in tqdm.tqdm(range(10)):\n",
    "            full_name = os.path.join(self.dir_name, list(os.listdir(self.dir_name))[file_num])\n",
    "            all_data = extract_tuples(full_name, n=self.n, threshold=self.threshold)\n",
    "            df = pd.DataFrame(all_data, columns=['L', 'p_ctrl', 'p_proj', 's_0'])\n",
    "            df_all_data = pd.concat([df_all_data, df])\n",
    "        return df_all_data\n",
    "\n",
    "    def plot(self):\n",
    "        # Simple plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Get unique L values from df_all_data\n",
    "        L_values = sorted(self.df_all_data['L'].unique())\n",
    "        p_vary_label = 'p_proj'\n",
    "        p_fixed_label = 'p_ctrl' if p_vary_label == 'p_proj' else 'p_proj'\n",
    "        p_fixed_value = self.df_all_data[p_fixed_label].unique()[0]\n",
    "        y_label = 'Mean EE'\n",
    "        title = f'Mean EE vs p_proj ({p_fixed_label}={p_fixed_value})'\n",
    "        # Plot each L value\n",
    "        for L in L_values:\n",
    "            # Filter data for this L value\n",
    "            L_data = self.df_all_data.query(f'L == {L}')\n",
    "            \n",
    "            # Group by p_proj and calculate mean and SEM\n",
    "            grouped = L_data.groupby(p_vary_label)['s_0'].agg([('mean', mean_func), ('sem', sem_func), ('variance', variance_func), ('sev', sev_func)]).reset_index()\n",
    "            # Plot mean with error bars\n",
    "            plt.errorbar(grouped[p_vary_label], \n",
    "                        grouped['mean'], \n",
    "                        yerr=grouped['sem'], \n",
    "                        label=f'L={L}', marker='o')\n",
    "\n",
    "        plt.xlabel(p_vary_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'/scratch/ty296/plots/s{self.n}_t{self.threshold}.png')\n",
    "        plt.show()\n",
    "\n",
    "    def save_plotting_data(self):\n",
    "        self.df_all_data.to_csv(f'/scratch/ty296/plots/s{self.n}_t{self.threshold}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_name = '/scratch/ty296/hdf5_data/p_ctrl0.4'\n",
    "# for threshold in np.logspace(-16, -5, 2):\n",
    "#     data = data_processor(dir_name, n=0, threshold=threshold)\n",
    "#     data.plot()\n",
    "#     data.save_plotting_data()\n",
    "# # result = df_all_data.groupby(['L', 'p_ctrl', 'p_proj'])['s_0'].agg([\n",
    "# #     ('mean', mean_func),\n",
    "# #     ('sem', sem_func), \n",
    "# #     ('variance', variance_func),\n",
    "# #     ('sev', sev_func)\n",
    "# # ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66810054e-15 2.78255940e-14 4.64158883e-13 7.74263683e-12\n",
      " 1.29154967e-10 2.15443469e-09 3.59381366e-08 5.99484250e-07\n",
      " 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "arr = np.logspace(-16, -5, 10)\n",
    "threshold = 1e-16\n",
    "mask = arr > threshold\n",
    "filtered_arr = arr[mask]\n",
    "print(filtered_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.3862943611198906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import read_hdf5_func\n",
    "\n",
    "read_hdf5_func.von_neumann_entropy_sv(arr, n=0, positivedefinite=False, threshold=1e-9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
